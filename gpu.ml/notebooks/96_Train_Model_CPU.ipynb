{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "import pylab\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "version = int(datetime.now().strftime(\"%s\"))\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "  log_device_placement=True,\n",
    ")\n",
    "print(config)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "print(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Training and Validation Data \n",
    "Note the use of `shuffle_batch()`.  This uses `RandomShuffleQueue` internally.\n",
    "\n",
    "The `min_after_dequeue` parameter is the sample size.  A larger value requires more RAM, but improves the randomness of the shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_queue = tf.train.string_input_producer([\n",
    "#  \"hdfs://127.0.0.1:39000/linear/training.csv\",\n",
    "#  \"hdfs://127.0.0.1:39000/linear/validation.csv\",\n",
    "    \"training.csv\",\n",
    "])\n",
    "\n",
    "training_reader = tf.TextLineReader()\n",
    "_, training_value = training_reader.read(training_queue)\n",
    "\n",
    "x_training, y_training = tf.decode_csv(training_value, [[0.0],[0.0]])\n",
    "\n",
    "x_training_batch, y_training_batch = \\\n",
    "    tf.train.shuffle_batch([x_training, y_training], \n",
    "                           batch_size=1000,\n",
    "                           capacity=2000,\n",
    "                           min_after_dequeue=1000)\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "training_coord = tf.train.Coordinator()\n",
    "\n",
    "training_enqueue_threads = tf.train.start_queue_runners(sess=sess, \n",
    "                                                        coord=training_coord)\n",
    "\n",
    "print(\"Training Enqueue Thread Pool Size: %d\" % len(training_enqueue_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# pylab.plot(x_train, y_train, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#pylab.plot(x_test, y_test, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    W = tf.get_variable(shape=[], name='weights')\n",
    "    print(W)\n",
    "\n",
    "    b = tf.get_variable(shape=[], name='bias')\n",
    "    print(b)\n",
    "\n",
    "#    x_observed_batch = tf.placeholder(shape=[None], \n",
    "#                                      dtype=tf.float32, \n",
    "#                                      name='x_observed')\n",
    "#    print(x_observed_batch)\n",
    "    \n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "#    y_pred_batch = W * x_observed_batch + b\n",
    "    y_pred_batch = W * x_training_batch + b\n",
    "    print(y_pred_batch)\n",
    "\n",
    "    \n",
    "with tf.device(\"/cpu:0\"):\n",
    "#    y_observed_batch = tf.placeholder(shape=[None], dtype=tf.float32, name='y_observed')\n",
    "#    print(y_observed_batch)\n",
    "    \n",
    "    loss_op = tf.reduce_mean(tf.square(y_pred_batch - y_training_batch))\n",
    "    optimizer_op = tf.train.GradientDescentOptimizer(0.025)\n",
    "    training_op = optimizer_op.minimize(loss_op)  \n",
    "\n",
    "    print(\"Loss Scalar: \", loss_op)\n",
    "    print(\"Optimizer Op: \", optimizer_op)\n",
    "    print(\"Training Op\", training_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Model Graph in Tensorboard\n",
    "\n",
    "Navigate to the Graph tab at this URL:\n",
    "\n",
    "http://[ip-address]:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Initialize Variables (Weights and Bias)\n",
    "The goal is to learn more accurate Weights and Bias during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    print(init_op)\n",
    "\n",
    "sess.run(init_op)\n",
    "print(\"W: %f\" % sess.run(W))\n",
    "print(\"b: %f\" % sess.run(b))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Accuracy of Initial Random Variables (Pre-Training)\n",
    "This should be relatively low because we have not trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def accuracy(x_param):\n",
    "#  return sess.run(loss_op, \n",
    "  #feed_dict={x_observed: x_param, y_observed: y_param})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#try:\n",
    "\n",
    "loss = sess.run(loss_op)\n",
    "\n",
    "print(\"Accuracy: %f\" % (loss*100))\n",
    "\n",
    "#except tf.errors.OutOfRangeError as e:\n",
    "#    print(\"Error '%s'\" % str(e))\n",
    "#finally:\n",
    "#    training_coord.request_stop()\n",
    "#    training_coord.join(enqueue_threads)\n",
    "\n",
    "#print(1 - sess.run(loss_op))\n",
    "                   #, feed_dict={x_observed: x_training_batch,\n",
    "                   #             y_observed: y_training_batch}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_summary_writer = tf.summary.FileWriter('root/tensorboard/linear/cpu/%s/training' % version, \n",
    "                                                 graph=tf.get_default_graph())\n",
    "\n",
    "#validation_summary_writer = tf.summary.FileWriter('root/tensorboard/linear/cpu/%s/validation' % version, \n",
    "#                                                 graph=tf.get_default_graph())\n",
    "\n",
    "# TODO\n",
    "#validation_summary_writer = tf.summary.FileWriter('root/tensorboard/linear/cpu/%s/validation' % version, \n",
    "#validation_summary_writer = tf.summary.FileWriter('root/tensorboard/linear/cpu/%s/validation' % version, \n",
    "#                                                   graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Loss Summary Operations for Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_summary_scalar_op = tf.summary.scalar('loss', loss_op)\n",
    "loss_summary_merge_all_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_metadata = tf.RunMetadata()\n",
    "\n",
    "max_steps = 400\n",
    "for step in range(max_steps - 1):\n",
    "    if (step < max_steps):\n",
    "        training_summary_log, _ = sess.run([loss_summary_merge_all_op, training_op]) \n",
    "#        validation_summary_log, _ = sess.run([loss_summary_merge_all_op, loss_op])\n",
    "    else:  \n",
    "        training_summary_log, _ = sess.run([loss_summary_merge_all_op, training_op],\n",
    "                                            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), \n",
    "                                            run_metadata=run_metadata)\n",
    "        \n",
    "#        validation_summary_log, _ = sess.run([loss_summary_merge_all_op, loss_op])\n",
    "    \n",
    "    trace = timeline.Timeline(step_stats=run_metadata.step_stats)    \n",
    "    with open('cpu-timeline.json', 'w') as trace_file:\n",
    "        trace_file.write(trace.generate_chrome_trace_format(show_memory=True))\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        training_summary_writer.add_summary(training_summary_log, step)\n",
    "        training_summary_writer.flush()\n",
    "#        validation_summary_writer.add_summary(validation_summary_log, step)\n",
    "#        validation_summary_writer.flush()\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run([W, b]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pylab.plot(x_train, y_train, '.', label=\"target\")\n",
    "#pylab.plot(x_train, sess.run(y_pred, feed_dict={x_observed: x_train, y_observed: y_train}), \".\", label=\"predicted\")\n",
    "#pylab.legend()\n",
    "#pylab.ylim(0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Loss Scalar Summary in Tensorboard\n",
    "\n",
    "Navigate to the Scalars tab at this URL:\n",
    "\n",
    "http://[ip-address]:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#loss = sess.run(loss_op)\n",
    "#print(1 - loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Graph and Variables for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import utils\n",
    "\n",
    "tensor_info_x_observed = utils.build_tensor_info(x_training_batch)\n",
    "print(tensor_info_x_observed)\n",
    "\n",
    "tensor_info_y_pred = utils.build_tensor_info(y_pred_batch)\n",
    "print(tensor_info_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO:\n",
    "\n",
    "#export_path = \"/root/models/linear/cpu/%s\" % version\n",
    "export_path = \"root/models/linear/cpu/serving/%s\" % version\n",
    "\n",
    "print(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "  builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "prediction_signature =  signature_def_utils.build_signature_def(\n",
    "    inputs = {'inputs': tensor_info_x_observed}, \n",
    "    outputs = {'outputs': tensor_info_y_pred}, \n",
    "    method_name = signature_constants.PREDICT_METHOD_NAME)            \n",
    "\n",
    "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "\n",
    "builder.add_meta_graph_and_variables(sess, \n",
    "  [tag_constants.SERVING],\n",
    "  signature_def_map={\"predict_linear\":prediction_signature,\n",
    "                      signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature}, \n",
    "                      legacy_init_op=legacy_init_op)\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Metagraph for Optimization and Transformation\n",
    "We will use this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TOOO:  root/\n",
    "saver = tf.train.Saver(max_to_keep=1, keep_checkpoint_every_n_hours=24)\n",
    "saver.export_meta_graph(\"root/models/linear/cpu/metagraph/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Saved Model on Disk\n",
    "\n",
    "You must replace `[version]` with the version number from above ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/linear/cpu/[version]\n",
    "ls -l /root/models/linear/cpu/metagraph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "#from tensorflow.python.framework import graph_io\n",
    "#graph_io.write_graph(sess.graph, \"/root/models/optimize_me/\", \"unoptimized_cpu.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "training_coord.request_stop()\n",
    "training_coord.join(enqueue_threads)\n",
    "\n",
    "#validation_coord.request_stop()\n",
    "#validation_coord.join(enqueue_threads)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:  View Accuracy of Trained Variables\n",
    "This should be relatively high after training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "validation_queue = tf.train.string_input_producer([\n",
    "#  \"hdfs://127.0.0.1:39000/linear/training.csv\",\n",
    "#  \"hdfs://127.0.0.1:39000/linear/validation.csv\",\n",
    "    \"validation.csv\",\n",
    "])\n",
    "\n",
    "validation_reader = tf.TextLineReader()\n",
    "_, validation_value = validation_reader.read(validation_queue)\n",
    "\n",
    "x_validation, y_validation = tf.decode_csv(validation_value, [[0.0],[0.0]])\n",
    "\n",
    "x_validation_batch, y_validation_batch = \\\n",
    "    tf.train.shuffle_batch([x_validation, y_validation], \n",
    "                           batch_size=100,\n",
    "                           capacity=2000,\n",
    "                           min_after_dequeue=1000)\n",
    "\n",
    "validation_coord = tf.train.Coordinator()\n",
    "\n",
    "validation_enqueue_threads = tf.train.start_queue_runners(sess=sess,\n",
    "                                                          coord=validation_coord)\n",
    "print(\"Validation Enqueue Thread Pool Size: %d\" % len(validation_enqueue_threads))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
